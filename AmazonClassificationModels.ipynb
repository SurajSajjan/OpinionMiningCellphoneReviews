{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import ast\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import sentiwordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S10rev = pd.read_csv(\"D:/AMOD/Final Research Project/imp/XR_data_sub.csv\").dropna()\n",
    "XRrev = pd.read_csv(\"D:/AMOD/Final Research Project/imp/S10_data_sub.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "S10rev['cleanContent']=S10rev['content'].map(lambda s:preprocess(s)) \n",
    "#S10rev.drop('content', axis=1, inplace=True)\n",
    "XRrev['cleanContent']=XRrev['content'].map(lambda s:preprocess(s)) \n",
    "#XRrev.drop('content', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>cleanContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Unbelievable product</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>unbelievable product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Crafted to precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>crafted precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Mobile at its best</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>mobile best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazon deal is mind blowing</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>amazon deal mind blowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>best place to get an IPhone</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>best place get iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3956</td>\n",
       "      <td>5</td>\n",
       "      <td>but it grows over you after something days of...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>grows something days use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3957</td>\n",
       "      <td>3</td>\n",
       "      <td>Not worth it</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3958</td>\n",
       "      <td>5</td>\n",
       "      <td>Exceptional phone with great faceid &amp; long las...</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>exceptional phone great faceid long lasting ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3959</td>\n",
       "      <td>5</td>\n",
       "      <td>Good phone</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>good phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>2</td>\n",
       "      <td>Heating so fast in use after 15 minute of use</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>heating fast use minute use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3961 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                            content  subjectivity  \\\n",
       "0          5                               Unbelievable product        1.0000   \n",
       "1          5                               Crafted to precision        0.0000   \n",
       "2          5                                 Mobile at its best        0.3000   \n",
       "3          5                        Amazon deal is mind blowing        0.0000   \n",
       "4          5                        best place to get an IPhone        0.3000   \n",
       "...      ...                                                ...           ...   \n",
       "3956       5   but it grows over you after something days of...        0.0000   \n",
       "3957       3                                       Not worth it        0.1000   \n",
       "3958       5  Exceptional phone with great faceid & long las...        0.5375   \n",
       "3959       5                                         Good phone        0.6000   \n",
       "3960       2      Heating so fast in use after 15 minute of use        0.6000   \n",
       "\n",
       "                                           cleanContent  \n",
       "0                                  unbelievable product  \n",
       "1                                     crafted precision  \n",
       "2                                           mobile best  \n",
       "3                              amazon deal mind blowing  \n",
       "4                                 best place get iphone  \n",
       "...                                                 ...  \n",
       "3956                           grows something days use  \n",
       "3957                                              worth  \n",
       "3958  exceptional phone great faceid long lasting ba...  \n",
       "3959                                         good phone  \n",
       "3960                        heating fast use minute use  \n",
       "\n",
       "[3961 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S10rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S10rev[\"subjectivity\"] = S10rev[\"subjectivity\"].apply(lambda x: 0 if x < 0.5 else 1)\n",
    "# select only relevant columns\n",
    "S10rev = S10rev[[\"subjectivity\", \"cleanContent\"]]\n",
    "\n",
    "XRrev[\"subjectivity\"] = XRrev[\"subjectivity\"].apply(lambda x: 0 if x < 0.5 else 1)\n",
    "# select only relevant columns\n",
    "XRrev = XRrev[[\"subjectivity\", \"cleanContent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>cleanContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unbelievable product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>crafted precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon deal mind blowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>best place get iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3956</td>\n",
       "      <td>0</td>\n",
       "      <td>grows something days use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3957</td>\n",
       "      <td>0</td>\n",
       "      <td>worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3958</td>\n",
       "      <td>1</td>\n",
       "      <td>exceptional phone great faceid long lasting ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3959</td>\n",
       "      <td>1</td>\n",
       "      <td>good phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>1</td>\n",
       "      <td>heating fast use minute use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3961 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subjectivity                                       cleanContent\n",
       "0                1                               unbelievable product\n",
       "1                0                                  crafted precision\n",
       "2                0                                        mobile best\n",
       "3                0                           amazon deal mind blowing\n",
       "4                0                              best place get iphone\n",
       "...            ...                                                ...\n",
       "3956             0                           grows something days use\n",
       "3957             0                                              worth\n",
       "3958             1  exceptional phone great faceid long lasting ba...\n",
       "3959             1                                         good phone\n",
       "3960             1                        heating fast use minute use\n",
       "\n",
       "[3961 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S10rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For S10\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "S10processed_features = vectorizer.fit_transform(S10rev['cleanContent']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S10processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainS10, X_testS10, y_trainS10, y_testS10 = train_test_split(S10processed_features, S10rev['subjectivity'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275    1\n",
       "1793    1\n",
       "1044    1\n",
       "248     0\n",
       "3620    0\n",
       "       ..\n",
       "3182    1\n",
       "3588    1\n",
       "1082    1\n",
       "3162    0\n",
       "3823    0\n",
       "Name: subjectivity, Length: 793, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testS10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_classifierS10 = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifierS10.fit(X_trainS10, y_trainS10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsS10 = text_classifierS10.predict(X_testS10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322  79]\n",
      " [ 60 332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82       401\n",
      "           1       0.81      0.85      0.83       392\n",
      "\n",
      "    accuracy                           0.82       793\n",
      "   macro avg       0.83      0.82      0.82       793\n",
      "weighted avg       0.83      0.82      0.82       793\n",
      "\n",
      "Accuracy: 0.8247162673392182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_testS10,predictionsS10))\n",
    "print(classification_report(y_testS10,predictionsS10))\n",
    "print(\"Accuracy:\",accuracy_score(y_testS10, predictionsS10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For XR\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "XRprocessed_features = vectorizer.fit_transform(XRrev['cleanContent']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainXR, X_testXR, y_trainXR, y_testXR = train_test_split(XRprocessed_features, XRrev['subjectivity'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_classifierXR = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifierXR.fit(X_trainXR, y_trainXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsXR = text_classifierXR.predict(X_testXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[295  40]\n",
      " [ 61 184]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       335\n",
      "           1       0.82      0.75      0.78       245\n",
      "\n",
      "    accuracy                           0.83       580\n",
      "   macro avg       0.83      0.82      0.82       580\n",
      "weighted avg       0.83      0.83      0.82       580\n",
      "\n",
      "Accuracy: 0.8258620689655173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_testXR,predictionsXR))\n",
    "print(classification_report(y_testXR,predictionsXR))\n",
    "print(\"Accuracy:\",accuracy_score(y_testXR, predictionsXR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "SVMS10 = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVMS10.fit(X_trainS10,y_trainS10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsS10 = SVMS10.predict(X_testS10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[352  49]\n",
      " [ 78 314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       401\n",
      "           1       0.87      0.80      0.83       392\n",
      "\n",
      "    accuracy                           0.84       793\n",
      "   macro avg       0.84      0.84      0.84       793\n",
      "weighted avg       0.84      0.84      0.84       793\n",
      "\n",
      "Accuracy: 0.8398486759142497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_testS10,predictionsS10))\n",
    "print(classification_report(y_testS10,predictionsS10))\n",
    "print(\"Accuracy:\",accuracy_score(y_testS10, predictionsS10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMXR = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVMXR.fit(X_trainXR,y_trainXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsXR = SVMXR.predict(X_testXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[302  33]\n",
      " [ 71 174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       335\n",
      "           1       0.84      0.71      0.77       245\n",
      "\n",
      "    accuracy                           0.82       580\n",
      "   macro avg       0.83      0.81      0.81       580\n",
      "weighted avg       0.82      0.82      0.82       580\n",
      "\n",
      "Accuracy: 0.8206896551724138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_testXR,predictionsXR))\n",
    "print(classification_report(y_testXR,predictionsXR))\n",
    "print(\"Accuracy:\",accuracy_score(y_testXR, predictionsXR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Base\n",
    "Mnb10 = naive_bayes.MultinomialNB()\n",
    "Mnb10.fit(X_trainS10,y_trainS10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsS10 = Mnb10.predict(X_testS10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[276 125]\n",
      " [ 65 327]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74       401\n",
      "           1       0.72      0.83      0.77       392\n",
      "\n",
      "    accuracy                           0.76       793\n",
      "   macro avg       0.77      0.76      0.76       793\n",
      "weighted avg       0.77      0.76      0.76       793\n",
      "\n",
      "Accuracy: 0.7604035308953342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_testS10,predictionsS10))\n",
    "print(classification_report(y_testS10,predictionsS10))\n",
    "print(\"Accuracy:\",accuracy_score(y_testS10, predictionsS10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Base\n",
    "MnbXR = naive_bayes.MultinomialNB()\n",
    "MnbXR.fit(X_trainXR,y_trainXR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsXR = MnbXR.predict(X_testXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[296  39]\n",
      " [ 71 174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       335\n",
      "           1       0.82      0.71      0.76       245\n",
      "\n",
      "    accuracy                           0.81       580\n",
      "   macro avg       0.81      0.80      0.80       580\n",
      "weighted avg       0.81      0.81      0.81       580\n",
      "\n",
      "Accuracy: 0.8103448275862069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_testXR,predictionsXR))\n",
    "print(classification_report(y_testXR,predictionsXR))\n",
    "print(\"Accuracy:\",accuracy_score(y_testXR, predictionsXR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
